{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbe09c3c",
   "metadata": {},
   "source": [
    "# Simple probabilistic bigram language model using torch\n",
    "\n",
    "Based on 1000 boy names, see how a language model manages to generate new random ones based on bigram of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a527ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b36c43d",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54aa59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 names loaded. Examples: ['Aarav', 'Aaron', 'Abdiel']..\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/names.txt\", \"r\") as f:\n",
    "    names = f.read().splitlines()\n",
    "    print(f\"{len(names)} names loaded. Examples: {names[:3]}..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e57e073",
   "metadata": {},
   "source": [
    "### Create vocab\n",
    "\n",
    "- Store all unique characters in a vocab. \n",
    "    - Also add a unique token indicating that a word starts and ends.\n",
    "- Keep capital letters (So we can see if model is smart enough to start names with capital later)\n",
    "- Create dicts to help us map between chars and index in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762a63bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab of size 54\n",
      "Index of character 'x' = 50\n",
      "Character of index 26 = Z\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = \"(\", \")\"\n",
    "vocab = [START_TOKEN] + sorted(list(set(\"\".join(names)))) + [END_TOKEN]\n",
    "print(f\"Vocab of size {len(vocab)}\")\n",
    "# Create \"string to index\" and \"index to string\" dicts for lookup purposes\n",
    "stoi = {s:i for i, s in enumerate(vocab)}\n",
    "itos = {i:s for i, s in enumerate(vocab)}\n",
    "print(f\"Index of character 'x' = {stoi['x']}\")\n",
    "print(f\"Character of index 26 = {itos[26]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "425f2b57",
   "metadata": {},
   "source": [
    "### Bigram Matrix\n",
    "\n",
    "Based on the dataset, we want to store the frequency of all bigrams in it. This is done by creating a matrix containing all chars in vocab.\n",
    "\n",
    "- Rows = first word, Columns = Second word\n",
    "    - Example: B[5, 10] = how many times bigram (5, 10) have occurred in dataset.\n",
    "\n",
    "We can use this matrix to compute probabilites of characters following each other later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ededf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.zeros((len(vocab), len(vocab)), dtype=torch.int32) # Bigram matrix\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11d2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    name_chars = [START_TOKEN] + list(name) + [END_TOKEN] # E.g. ['(', 'A', 'd', 'a', 'm', ')']\n",
    "    for c1, c2 in zip(name_chars, name_chars[1:]): # E.g. c1='A', c2='d'\n",
    "        B[stoi[c1], stoi[c2]] += 1 # Add count to (c1, c2) bigram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0d29ce1",
   "metadata": {},
   "source": [
    "Print some examples from Bigram matrix filled with frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c1f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigram ck occurred 17 times in dataset\n",
      "The bigram ry occurred 19 times in dataset\n",
      "The bigram kr occurred 0 times in dataset\n"
     ]
    }
   ],
   "source": [
    "bigram_samples = [\"ck\", \"ry\", \"kr\"]\n",
    "for sample in bigram_samples:\n",
    "    print(f\"The bigram {sample} occurred {B[stoi[sample[0]], stoi[sample[1]]].item()} times in dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ebb5103",
   "metadata": {},
   "source": [
    "### Probability matrix (based on bigram frequencies)\n",
    "\n",
    "This is created by dividing each item by the sum of its row. \n",
    "\n",
    "For example, if this row contains frequency of char 'x': `[0, 2, 1, 3]`, then the sum of the row is:\n",
    "```\n",
    "0+2+1+3 = 6\n",
    "```\n",
    "We can then compute the probability row as:\n",
    "```\n",
    "[0/6, 2/6, 1/6, 3/6] = [0, 0.33, 0.16, 0.5]\n",
    "```\n",
    "\n",
    "Example of shapes and sum in torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029dded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n",
      "E have shape torch.Size([2, 3])\n",
      "First row = tensor([1, 2, 3])\n",
      "First column = tensor([1, 3])\n",
      "Sum on axis 0: tensor([[4, 6, 8]])\n",
      "Sum on axis 1: tensor([[ 6],\n",
      "        [12]])\n",
      "Sum on axis 0 shape: torch.Size([3]) (keepdim=False)\n",
      "Sum on axis 0 shape: torch.Size([1, 3]) (keepdim=True)\n",
      "Sum on axis 1 shape: torch.Size([2]) (keepdim=False)\n",
      "Sum on axis 1 shape: torch.Size([2, 1]) (keepdim=True)\n"
     ]
    }
   ],
   "source": [
    "E = torch.tensor([[1, 2, 3], [3, 4, 5]])\n",
    "print(E)\n",
    "print(f\"E have shape {E.shape}\")\n",
    "print(f\"First row = {E[0, :]}\\nFirst column = {E[:, 0]}\")\n",
    "print(f\"Sum on axis 0: {E.sum(0, keepdim=True)}\\nSum on axis 1: {E.sum(1, keepdim=True)}\")\n",
    "print(f\"Sum on axis 0 shape: {E.sum(0, keepdim=False).shape} (keepdim=False)\")\n",
    "print(f\"Sum on axis 0 shape: {E.sum(0, keepdim=True).shape} (keepdim=True)\")\n",
    "print(f\"Sum on axis 1 shape: {E.sum(1, keepdim=False).shape} (keepdim=False)\")\n",
    "print(f\"Sum on axis 1 shape: {E.sum(1, keepdim=True).shape} (keepdim=True)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fa91327",
   "metadata": {},
   "source": [
    "Compute the matrix and print some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace6bfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P shape: torch.Size([54, 54])\n",
      "Probability of 'c' followed by 'k' = 0.11042945086956024\n",
      "Row 5 contains probabilities of all words following char E. The sum of the row is (should be 1) = 1.0000001192092896.\n",
      "The most probable char following E is l\n"
     ]
    }
   ],
   "source": [
    "P = (B+1).float() # add 1 to bigram matrix in order to avoid -inf on bigrams that havent been seen\n",
    "P /= P.sum(1, keepdims=True) # divide by column vector containing sum of each row. 54x54 / 54x1\n",
    "print(f\"P shape: {P.shape}\")\n",
    "print(f\"Probability of 'c' followed by 'k' = {P[stoi['c'], stoi['k']]}\")\n",
    "print((\n",
    "    f\"Row 5 contains probabilities of all words following char {itos[5]}.\" \n",
    "    f\" The sum of the row is (should be 1) = {P[5].sum()}.\"\n",
    "    f\"\\nThe most probable char following {itos[5]} is {itos[P[5].argmax().item()]}\"\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14fde8bd",
   "metadata": {},
   "source": [
    "# Generate random names\n",
    "\n",
    "The loop works like this:\n",
    "- Based on the start token, sample a 'probable' next char\n",
    "- Keep sampling probable next chars based on previous sampled char, until the end token is sampled\n",
    "\n",
    "Expect terrible names because the model only knows bigram context when generating, BUT it should be able to start the names with one of the capital letters when it sees a START_TOKEN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba76600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you doing today Mr. DoDLMard\n",
      "How are you doing today Mr. Grenenc\n",
      "How are you doing today Mr. Omnthericknn\n",
      "How are you doing today Mr. MsedJohyliamoto\n",
      "How are you doing today Mr. Jacondesen\n",
      "How are you doing today Mr. Caiejallele\n",
      "How are you doing today Mr. ChmmiwwZg(ACoreso\n",
      "How are you doing today Mr. AzyamastVmen\n",
      "How are you doing today Mr. ChandukArer\n",
      "How are you doing today Mr. Ky\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "for i in range(num):  \n",
    "    name = []\n",
    "    c1 = stoi[START_TOKEN]\n",
    "    while True:\n",
    "        c2_probs = P[c1] # probability vector of chars following c1\n",
    "        # get c2 by multinomial sampling on the probabilty vector\n",
    "        c2 = torch.multinomial(c2_probs, num_samples=1, replacement=True).item()\n",
    "        if c2 == stoi[END_TOKEN]: break\n",
    "        name.append(itos[c2])\n",
    "        c1 = c2 # c2 is first char in next iteration\n",
    "    print(f\"How are you doing today Mr. {''.join(name)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_bigram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcdb541eee026b553c5777d251e843d26bc60d4a753b37888e8eeecefbd9d6ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
